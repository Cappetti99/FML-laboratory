{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca [1/5], Loss: 0.2395, Accuracy: 92.92%\n",
      "Epoca [2/5], Loss: 0.0819, Accuracy: 97.53%\n",
      "Epoca [3/5], Loss: 0.0537, Accuracy: 98.39%\n",
      "Epoca [4/5], Loss: 0.0366, Accuracy: 98.83%\n",
      "Epoca [5/5], Loss: 0.0267, Accuracy: 99.17%\n",
      "Accuracy sui test: 98.22%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.fft\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Definizione di una CNN classica\n",
    "class ClassicCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ClassicCNN, self).__init__()\n",
    "        # Layer convoluzionali\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)  # Convoluzione: 1 canale in ingresso, 32 canali in uscita\n",
    "        self.fc1 = nn.Linear(8 * 28 * 28, 128)  # Fully connected: 64*7*7 è il numero di neuroni dopo il pooling\n",
    "        self.fc2 = nn.Linear(128, 10)  # Ultimo layer per le 10 classi di MNIST\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Passaggio attraverso i layer convoluzionali\n",
    "        x = torch.relu(self.conv1(x)) # ReLU e max pooling dopo la convoluzione\n",
    "        \n",
    "        # Flatten per passare ai layer fully connected\n",
    "        x = x.view(x.size(0), -1)  # Flatten l'output dei layer convoluzionali\n",
    "\n",
    "        # Passaggio attraverso i layer fully connected\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)  # Output finale (logits per 10 classi)\n",
    "        return x\n",
    "\n",
    "# Caricamento dataset MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])  # Normalizzazione\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ClassicCNN().to(device)  # Creazione del modello e trasferimento su GPU/CPU\n",
    "criterion = nn.CrossEntropyLoss()  # Funzione di perdita\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Ottimizzatore Adam\n",
    "\n",
    "# Addestramento della rete\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoca [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "model.eval()  # Imposta il modello in modalità di valutazione\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disabilita il calcolo dei gradienti per il test\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Accuracy sui test: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca [1/5], Loss: 0.4056, Accuracy: 88.72%\n",
      "Epoca [2/5], Loss: 0.3193, Accuracy: 91.00%\n",
      "Epoca [3/5], Loss: 0.3016, Accuracy: 91.35%\n",
      "Epoca [4/5], Loss: 0.2906, Accuracy: 91.69%\n",
      "Epoca [5/5], Loss: 0.2836, Accuracy: 91.99%\n",
      "Accuracy sui test: 91.74%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.fft\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Funzione per passare da dominio del tempo a dominio della frequenza\n",
    "def to_frequency_domain(x):\n",
    "    return torch.fft.fft2(x)\n",
    "\n",
    "# Funzione per tornare al dominio del tempo\n",
    "def to_time_domain(x):\n",
    "    return torch.fft.ifft2(x).real\n",
    "\n",
    "# Layer di moltiplicazione elemento per elemento nel dominio della frequenza\n",
    "class FrequencyConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(FrequencyConv, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        # Definizione dei pesi nel dominio della frequenza\n",
    "        self.weights = nn.Parameter(torch.randn(1, out_channels, in_channels, kernel_size, kernel_size, dtype=torch.cfloat))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, _, H, W = x.shape\n",
    "        x_freq = to_frequency_domain(x)  # Trasformata di Fourier\n",
    "        \n",
    "        # Creazione di un kernel della stessa dimensione delle feature in ingresso\n",
    "        kernel_padded = torch.zeros((batch_size, self.out_channels, self.in_channels, H, W), dtype=torch.cfloat, device=x.device)\n",
    "        kernel_padded[:, :, :, :self.kernel_size, :self.kernel_size] = self.weights  # Padding\n",
    "        \n",
    "        kernel_freq = to_frequency_domain(kernel_padded)  # Trasformata di Fourier del kernel\n",
    "        \n",
    "        out_freq = x_freq.unsqueeze(1) * kernel_freq  # Moltiplicazione elemento per elemento\n",
    "        out_time = to_time_domain(out_freq)  # Ritorno nel dominio del tempo\n",
    "        \n",
    "        return out_time.sum(dim=2)  # Somma lungo i canali in ingresso\n",
    "    \n",
    "# Definizione di CEMNet\n",
    "class CEMNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CEMNet, self).__init__()\n",
    "        self.conv1 = FrequencyConv(1, 8, 3)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.fc1 = nn.Linear(8 * 28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Caricamento dataset MNIST\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CEMNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Addestramento della rete\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    for images, labels in trainloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoca [{epoch+1}/{num_epochs}], Loss: {running_loss/len(trainloader):.4f}, Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# Valutazione del modello sui dati di test\n",
    "model.eval()  # Imposta il modello in modalità di valutazione\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # Disabilita il calcolo dei gradienti per il test\n",
    "    for images, labels in testloader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "test_accuracy = 100 * correct / total\n",
    "print(f'Accuracy sui test: {test_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ihodlkjsaldfnlqwesajn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
