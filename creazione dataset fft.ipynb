{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class FFTTransform:\n",
    "    def __call__(self, img):\n",
    "        img_tensor = transforms.functional.to_tensor(img)\n",
    "        padded_img = F.pad(img_tensor, (0, 4, 0, 4))\n",
    "        fft_result = torch.fft.fft2(padded_img)\n",
    "        fft_magnitude = torch.abs(fft_result)\n",
    "        fft_magnitude = fft_magnitude / fft_magnitude.max()\n",
    "        return fft_magnitude\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    FFTTransform(),\n",
    "])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_images = trainset.data.unsqueeze(1)\n",
    "test_images = testset.data.unsqueeze(1)\n",
    "\n",
    "torch.save({\n",
    "    'train_images': train_images,\n",
    "    'train_labels': trainset.targets,\n",
    "    'test_images': test_images,\n",
    "    'test_labels': testset.targets,\n",
    "}, './transformed_mnist.pt')\n",
    "\n",
    "print(\"Dataset saved to disk.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CIFR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "\n",
    "class FFTTransform:\n",
    "    def __call__(self, img):\n",
    "        img_tensor = transforms.functional.to_tensor(img)\n",
    "        padded_img = F.pad(img_tensor, (0, 2, 0, 2))\n",
    "        fft_result = torch.fft.fft2(padded_img)\n",
    "        fft_magnitude = torch.abs(fft_result)\n",
    "        fft_magnitude = fft_magnitude / fft_magnitude.max()\n",
    "        return fft_magnitude\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    FFTTransform(),\n",
    "])\n",
    "\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "train_images = torch.stack([img for img, _ in trainset])\n",
    "test_images = torch.stack([img for img, _ in testset])\n",
    "\n",
    "torch.save({\n",
    "    'train_images': train_images,\n",
    "    'train_labels': torch.tensor(trainset.targets),\n",
    "    'test_images': test_images,\n",
    "    'test_labels': torch.tensor(testset.targets),\n",
    "}, './transformed_cifar10.pt')\n",
    "\n",
    "print(\"Dataset saved to disk.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "\n",
    "class HSVTransform:\n",
    "    def __call__(self, img):\n",
    "        img = img.convert(\"HSV\")  # Converte l'immagine in HSV\n",
    "        img_tensor = TF.to_tensor(img)  # Converte in tensore PyTorch\n",
    "        padded_img = F.pad(img_tensor, (0, 2, 0, 2))\n",
    "        fft_result = torch.fft.fft2(padded_img)\n",
    "        fft_magnitude = torch.abs(fft_result)\n",
    "        fft_magnitude = fft_magnitude / fft_magnitude.max()\n",
    "        return fft_magnitude\n",
    "\n",
    "# Definiamo la trasformazione\n",
    "transform = transforms.Compose([\n",
    "    HSVTransform(),\n",
    "])\n",
    "\n",
    "# Carichiamo il dataset con la nuova trasformazione\n",
    "trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Convertiamo le immagini in tensori\n",
    "train_images = torch.stack([img for img, _ in trainset])\n",
    "test_images = torch.stack([img for img, _ in testset])\n",
    "\n",
    "# Salviamo il dataset trasformato\n",
    "torch.save({\n",
    "    'train_images': train_images,\n",
    "    'train_labels': torch.tensor(trainset.targets),\n",
    "    'test_images': test_images,\n",
    "    'test_labels': torch.tensor(testset.targets),\n",
    "}, './transformed_cifar10_hsv.pt')\n",
    "\n",
    "print(\"Dataset in formato HSV salvato su disco.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastai.data.external import untar_data, URLs\n",
    "\n",
    "path = untar_data(URLs.IMAGEWOOF)\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "path = untar_data(URLs.IMAGEWOOF)\n",
    "dls = ImageDataLoaders.from_folder(path, valid='val', item_tfms=Resize(224))\n",
    "\n",
    "dls.show_batch(max_n=9, figsize=(7,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Un quarto del dataset con random crop a 224x224, padding e trasformazione HSV salvato su disco.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import os\n",
    "import random\n",
    "\n",
    "class HSVTransform:\n",
    "    def __call__(self, img):\n",
    "        # Applichiamo il padding solo se l'immagine è più piccola di 224x224\n",
    "        width, height = img.size\n",
    "        padding = (0, 0, 0, 0)  # Padding: (left, top, right, bottom)\n",
    "\n",
    "        if width < 224 or height < 224:\n",
    "            padding = (max(0, (224 - width) // 2), max(0, (224 - height) // 2),\n",
    "                       max(0, (224 - width + 1) // 2), max(0, (224 - height + 1) // 2))\n",
    "\n",
    "        img = TF.pad(img, padding)  # Aggiungi il padding\n",
    "        img = img.convert(\"HSV\")  # Converte l'immagine in HSV\n",
    "        img_tensor = TF.to_tensor(img)  # Converte in tensore PyTorch\n",
    "        fft_result = torch.fft.fft2(img_tensor)\n",
    "        fft_magnitude = torch.abs(fft_result)\n",
    "        fft_magnitude = fft_magnitude / fft_magnitude.max()\n",
    "        return fft_magnitude\n",
    "\n",
    "# Definiamo la trasformazione\n",
    "transform = transforms.Compose([\n",
    "    HSVTransform(),  # Trasformazione HSV e FFT\n",
    "    transforms.RandomCrop(224),  # Random crop a 224x224\n",
    "])\n",
    "\n",
    "# Percorso al dataset\n",
    "dataset_path = '/home/lapo-chiostrini/.fastai/data/imagewoof2'\n",
    "\n",
    "# Carichiamo il dataset con la nuova trasformazione\n",
    "trainset = ImageFolder(root=os.path.join(dataset_path, 'train'), transform=transform)\n",
    "testset = ImageFolder(root=os.path.join(dataset_path, 'val'), transform=transform)\n",
    "\n",
    "# Otteniamo un quarto delle immagini\n",
    "train_size = len(trainset)\n",
    "test_size = len(testset)\n",
    "\n",
    "train_indices = random.sample(range(train_size), train_size // 4)\n",
    "test_indices = random.sample(range(test_size), test_size // 4)\n",
    "\n",
    "train_subset = Subset(trainset, train_indices)\n",
    "test_subset = Subset(testset, test_indices)\n",
    "\n",
    "# Creiamo i DataLoader\n",
    "trainloader = DataLoader(train_subset, batch_size=64, shuffle=True)\n",
    "testloader = DataLoader(test_subset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Convertiamo le immagini in tensori\n",
    "train_images = torch.stack([img for img, _ in train_subset])\n",
    "test_images = torch.stack([img for img, _ in test_subset])\n",
    "\n",
    "# Salviamo il dataset trasformato\n",
    "torch.save({\n",
    "    'train_images': train_images,\n",
    "    'train_labels': torch.tensor([trainset.targets[i] for i in train_indices]),\n",
    "    'test_images': test_images,\n",
    "    'test_labels': torch.tensor([testset.targets[i] for i in test_indices]),\n",
    "}, './transformed_imagewoof_hsv_quarter_randomcrop_with_padding.pt')\n",
    "\n",
    "print(\"Un quarto del dataset con random crop a 224x224, padding e trasformazione HSV salvato su disco.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
