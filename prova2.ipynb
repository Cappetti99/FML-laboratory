{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-19 13:20:38.596859: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-19 13:20:38.613670: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-19 13:20:38.618318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-19 13:20:38.628954: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1734610840.683300   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610840.724712   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610840.724923   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) disponibile/i.\n",
      "Forma di X_train_dct: (60000, 28, 28)\n",
      "Forma di X_test_dct: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input,Layer\n",
    "from scipy.fftpack import dct\n",
    "# Configurazione per la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limita la memoria GPU allocata (opzionale)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # Permette allocazione dinamica della memoria\n",
    "        print(f\"{len(gpus)} GPU(s) disponibile/i.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Nessuna GPU disponibile, verrà usata la CPU.\")\n",
    "\n",
    "# Carica il dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def apply_dct(data):\n",
    "    # Esegui la DCT bidimensionale sull'immagine\n",
    "    # La `type=2` rappresenta la DCT-II, che è la più comune\n",
    "    return dct(dct(data, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "\n",
    "X_train_dct = np.array([apply_dct(img) for img in X_train])  # Applica la DCT alle immagini di training\n",
    "X_test_dct = np.array([apply_dct(img) for img in X_test])  # Applica la DCT alle immagini di test\n",
    "\n",
    "\n",
    "print(\"Forma di X_train_dct:\", X_train_dct.shape)\n",
    "print(\"Forma di X_test_dct:\", X_test_dct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro 1:\n",
      "[[ 2.01490484  0.02273739  0.20807512]\n",
      " [ 0.19517652  0.03093649 -0.28780002]\n",
      " [ 0.09046218 -0.66583017  0.2467256 ]]\n",
      "\n",
      "Filtro 2:\n",
      "[[ 1.80026887 -0.39697953 -0.4168278 ]\n",
      " [ 0.08682446  0.21602908  0.34059942]\n",
      " [-0.18385539  0.19957312 -0.20151331]]\n",
      "\n",
      "Filtro 3:\n",
      "[[ 1.22126617  0.0052015  -0.52742093]\n",
      " [ 0.33784643  0.31413849  0.04425967]\n",
      " [-0.09331925  0.25581318  0.4074057 ]]\n",
      "\n",
      "Filtro 4:\n",
      "[[ 1.74423621  0.08263877  0.03724123]\n",
      " [ 0.26600278  0.27898351 -0.49202909]\n",
      " [ 0.21418271  0.25432162  0.45278172]]\n",
      "\n",
      "Filtro 5:\n",
      "[[ 1.746036   -0.06963857  0.11756317]\n",
      " [-0.29673794 -0.22064443 -0.29941863]\n",
      " [-0.21229563 -0.10733693 -0.07005113]]\n",
      "\n",
      "Filtro 6:\n",
      "[[ 1.41770229  0.10683736 -0.28181234]\n",
      " [-0.14704586  0.53902321  0.40452269]\n",
      " [ 0.14531329  0.28576959  0.2211669 ]]\n",
      "\n",
      "Filtro 7:\n",
      "[[ 1.72189739 -0.38257106 -0.4899413 ]\n",
      " [-0.35985546 -0.0539674  -0.0224057 ]\n",
      " [ 0.40644888 -0.14266853  0.32575866]]\n",
      "\n",
      "Filtro 8:\n",
      "[[ 1.82956308 -0.18236075  0.27479529]\n",
      " [ 0.14967565  0.66625764  0.09246519]\n",
      " [ 0.06291381 -0.04205565 -0.20186467]]\n",
      "\n",
      "Filtro 9:\n",
      "[[ 2.07546338  0.11743945  0.69638656]\n",
      " [ 0.06735629 -0.07379448  0.33033259]\n",
      " [ 0.07974056  0.03979426 -0.19553259]]\n",
      "\n",
      "Filtro 10:\n",
      "[[ 1.69782717  0.17266976 -0.5309653 ]\n",
      " [-0.09989343  0.57176135 -0.40378717]\n",
      " [-0.03795604 -0.26620533  0.11440032]]\n",
      "\n",
      "Filtro 11:\n",
      "[[ 1.3470285  -0.03985447 -0.53304823]\n",
      " [-0.02789732  0.25936348  0.06935208]\n",
      " [ 0.08606751 -0.37133744 -0.060692  ]]\n",
      "\n",
      "Filtro 12:\n",
      "[[ 1.53560418  0.02757742 -0.20682493]\n",
      " [ 0.35638906 -0.51157697  0.12439341]\n",
      " [ 0.12702794 -0.3403231  -0.44764333]]\n",
      "\n",
      "Filtro 13:\n",
      "[[ 0.84793324  0.0612682   0.02259987]\n",
      " [ 0.11895746 -0.0189673   0.08605401]\n",
      " [ 0.14871813 -0.18764635 -0.02603014]]\n",
      "\n",
      "Filtro 14:\n",
      "[[ 1.46012457e+00 -4.49286004e-01  4.54655848e-02]\n",
      " [ 1.51236256e-01  1.44364016e-02 -3.09070921e-02]\n",
      " [ 1.05929899e-03  2.34658941e-01  1.60043566e-01]]\n",
      "\n",
      "Filtro 15:\n",
      "[[ 1.42008226  0.12238468  0.0712852 ]\n",
      " [ 0.07178296 -0.29866726 -0.28386983]\n",
      " [ 0.23214984 -0.2634402   0.34949972]]\n",
      "\n",
      "Filtro 16:\n",
      "[[ 1.43755966  0.46682793 -0.05812024]\n",
      " [-0.00689295 -0.0348083  -0.47384949]\n",
      " [-0.12928635  0.27152555 -0.20537351]]\n",
      "\n",
      "Filtro 17:\n",
      "[[ 1.71182564 -0.01078331 -0.04176858]\n",
      " [ 0.62216357 -0.09187378 -0.10980273]\n",
      " [ 0.28231105  0.04198202 -0.06370848]]\n",
      "\n",
      "Filtro 18:\n",
      "[[ 1.07032849 -0.3782536  -0.35607118]\n",
      " [ 0.12754717 -0.24033281  0.15276202]\n",
      " [ 0.25507782 -0.33194109  0.27874809]]\n",
      "\n",
      "Filtro 19:\n",
      "[[ 1.357553    0.00856563  0.10671054]\n",
      " [-0.25705584 -0.13485212  0.15985035]\n",
      " [-0.06187517  0.11271101  0.02559591]]\n",
      "\n",
      "Filtro 20:\n",
      "[[ 1.1723702  -0.32740797  0.22847723]\n",
      " [ 0.25337048 -0.14279714  0.27289627]\n",
      " [-0.14663262 -0.25400002  0.5728144 ]]\n",
      "\n",
      "Filtro 21:\n",
      "[[ 1.36449909  0.06243184 -0.01435905]\n",
      " [ 0.2630445  -0.06369506  0.03098931]\n",
      " [ 0.13568949  0.49477685  0.14746622]]\n",
      "\n",
      "Filtro 22:\n",
      "[[ 2.08001188 -0.04039205 -0.02181712]\n",
      " [-0.3075797   0.47248926 -0.04120977]\n",
      " [-0.15806146 -0.0101356  -0.52220247]]\n",
      "\n",
      "Filtro 23:\n",
      "[[ 1.60931065 -0.43840109 -0.10323786]\n",
      " [ 0.33559067 -0.13232402 -0.19865463]\n",
      " [ 0.12701124  0.40202679  0.05288826]]\n",
      "\n",
      "Filtro 24:\n",
      "[[ 1.47021611 -0.10269399  0.37022779]\n",
      " [ 0.208294    0.44711321 -0.30166218]\n",
      " [ 0.37379951 -0.01046707  0.16065268]]\n",
      "\n",
      "Filtro 25:\n",
      "[[ 0.93629654  0.02748744  0.22602624]\n",
      " [-0.05519034 -0.33859715  0.12536583]\n",
      " [-0.25879173 -0.212435    0.09857152]]\n",
      "\n",
      "Filtro 26:\n",
      "[[ 1.64017198  0.34918181  0.29384552]\n",
      " [ 0.20286364  0.21304926 -0.04472462]\n",
      " [-0.32804944 -0.0481566   0.49867084]]\n",
      "\n",
      "Filtro 27:\n",
      "[[ 1.83123899  0.10901701 -0.22902313]\n",
      " [-0.46517124 -0.18025474 -0.2000575 ]\n",
      " [-0.19907374  0.09843286  0.09203116]]\n",
      "\n",
      "Filtro 28:\n",
      "[[ 1.26188003  0.05799445  0.02915422]\n",
      " [-0.34031327  0.48838232  0.45585799]\n",
      " [ 0.12636604 -0.25132427 -0.39351253]]\n",
      "\n",
      "Filtro 29:\n",
      "[[ 1.57001672  0.02921879  0.18938211]\n",
      " [ 0.30004278 -0.31410589 -0.4475795 ]\n",
      " [ 0.31043835 -0.11091988 -0.05613053]]\n",
      "\n",
      "Filtro 30:\n",
      "[[ 1.19995168 -0.45038728 -0.15761884]\n",
      " [ 0.19792494 -0.1961922   0.22021228]\n",
      " [-0.3032427  -0.45282515  0.48380743]]\n",
      "\n",
      "Filtro 31:\n",
      "[[ 1.28340201 -0.39712663 -0.16445024]\n",
      " [ 0.63724544 -0.32592487 -0.22230467]\n",
      " [-0.43406128 -0.0904787  -0.12229248]]\n",
      "\n",
      "Filtro 32:\n",
      "[[ 1.71213197  0.40860722 -0.37961922]\n",
      " [-0.20325368 -0.16316576 -0.64991334]\n",
      " [-0.41461403  0.0203641   0.08085204]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtri = np.random.rand(32, 3, 3)\n",
    "\n",
    "filtri_dct = np.array([apply_dct(img) for img in filtri])  # Applica la DCT alle immagini di training\n",
    "\n",
    "\n",
    "# Stampa i filtri generati\n",
    "for i, filtro in enumerate(filtri_dct):\n",
    "    print(f\"Filtro {i+1}:\\n{filtro}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma di X_train_dct: (60000, 28, 3)\n",
      "Forma di X_test_dct: (10000, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "#rimuovi tutte le colonne apparte prime 3 in tutte le immagini di training e test\n",
    "X_train_dct = X_train_dct[:, :, :3]\n",
    "X_test_dct = X_test_dct[:, :, :3]\n",
    "\n",
    "\n",
    "\n",
    "#printa le shape\n",
    "\n",
    "print(\"Forma di X_train_dct:\", X_train_dct.shape)\n",
    "print(\"Forma di X_test_dct:\", X_test_dct.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDCTLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IDCTLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # IDCT lungo l'asse delle righe e poi delle colonne\n",
    "        def idct_2d(tensor):\n",
    "            # Applica la IDCT lungo le righe (asse=-1)\n",
    "            x = tf.signal.idct(tensor, type=2, norm='ortho', axis=-1)\n",
    "            # Trasponi per applicare la IDCT lungo le colonne\n",
    "            x = tf.transpose(x, perm=[0, 1, 3, 2])  # Scambia -2 (righe) con -1 (colonne)\n",
    "            x = tf.signal.idct(x, type=2, norm='ortho', axis=-1)\n",
    "            # Ritorna alla disposizione originale\n",
    "            x = tf.transpose(x, perm=[0, 1, 3, 2])  # Ritorna alla forma originale\n",
    "            return x\n",
    "\n",
    "        # Applica la IDCT batch-wise e canale per canale\n",
    "        return idct_2d(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734610842.567370   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610842.567706   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610842.567921   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610842.686882   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610842.687104   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1734610842.687249   10405 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-12-19 13:20:42.687350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5501 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28, 3)),  \n",
    "    Flatten(),             \n",
    "    Dense(228, activation='relu'),\n",
    "    Dense(576, activation='relu'),\n",
    "    Dense(1152, activation='relu'),\n",
    "    Reshape((3, 3, 128)),\n",
    "    IDCTLayer(),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734610844.391328   10460 service.cc:146] XLA service 0x7c9e10002840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1734610844.391350   10460 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n",
      "2024-12-19 13:20:44.419633: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-12-19 13:20:44.580085: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 63/750\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4206 - loss: 36.8043"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1734610846.111395   10460 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6864 - loss: 6.7485 - val_accuracy: 0.7990 - val_loss: 0.5650\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8192 - loss: 0.5059 - val_accuracy: 0.8278 - val_loss: 0.4835\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8360 - loss: 0.4462 - val_accuracy: 0.8346 - val_loss: 0.4635\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8493 - loss: 0.4105 - val_accuracy: 0.8317 - val_loss: 0.4646\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8531 - loss: 0.3902 - val_accuracy: 0.8393 - val_loss: 0.4531\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3680 - val_accuracy: 0.8404 - val_loss: 0.4576\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8661 - loss: 0.3559 - val_accuracy: 0.8475 - val_loss: 0.4404\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3434 - val_accuracy: 0.8487 - val_loss: 0.4576\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3349 - val_accuracy: 0.8407 - val_loss: 0.4640\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.3243 - val_accuracy: 0.8507 - val_loss: 0.4404\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.3198 - val_accuracy: 0.8374 - val_loss: 0.4701\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3041 - val_accuracy: 0.8577 - val_loss: 0.4370\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3002 - val_accuracy: 0.8506 - val_loss: 0.4683\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.2865 - val_accuracy: 0.8519 - val_loss: 0.4799\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8955 - loss: 0.2841 - val_accuracy: 0.8578 - val_loss: 0.4929\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9017 - loss: 0.2699 - val_accuracy: 0.8417 - val_loss: 0.5259\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9004 - loss: 0.2657 - val_accuracy: 0.8572 - val_loss: 0.4957\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.2547 - val_accuracy: 0.8609 - val_loss: 0.4935\n",
      "Epoch 19/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.2493 - val_accuracy: 0.8578 - val_loss: 0.4873\n",
      "Epoch 20/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2322 - val_accuracy: 0.8581 - val_loss: 0.5154\n",
      "Epoch 21/30\n",
      "\u001b[1m672/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9173 - loss: 0.2257"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Addestra il modello\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_dct, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Valuta il modello\u001b[39;00m\n\u001b[1;32m     10\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test_dct, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:217\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m ):\n\u001b[1;32m    216\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_has_value(\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m    173\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalHasValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, optional)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compila il modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(X_train_dct, y_train, epochs=30, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Valuta il modello\n",
    "test_loss, test_acc = model.evaluate(X_test_dct, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) disponibile/i.\n",
      "Epoch 1/10\n",
      "\u001b[1m319/750\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7094 - loss: 10.2375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Addestra il modello\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Valuta il modello\u001b[39;00m\n\u001b[1;32m     43\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:217\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m ):\n\u001b[1;32m    216\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_has_value(\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m    173\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalHasValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, optional)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape\n",
    "\n",
    "# Configurazione per la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limita la memoria GPU allocata (opzionale)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # Permette allocazione dinamica della memoria\n",
    "        print(f\"{len(gpus)} GPU(s) disponibile/i.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Nessuna GPU disponibile, verrà usata la CPU.\")\n",
    "\n",
    "# Carica il dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# Crea il modello\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compila il modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Valuta il modello\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
