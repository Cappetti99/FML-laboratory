{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) disponibile/i.\n",
      "Forma di X_train_dct: (60000, 28, 28)\n",
      "Forma di X_test_dct: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape, Input,Layer\n",
    "from scipy.fftpack import dct\n",
    "# Configurazione per la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limita la memoria GPU allocata (opzionale)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # Permette allocazione dinamica della memoria\n",
    "        print(f\"{len(gpus)} GPU(s) disponibile/i.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Nessuna GPU disponibile, verrà usata la CPU.\")\n",
    "\n",
    "# Carica il dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "def apply_dct(data):\n",
    "    # Esegui la DCT bidimensionale sull'immagine\n",
    "    # La `type=2` rappresenta la DCT-II, che è la più comune\n",
    "    return dct(dct(data, axis=0, norm='ortho'), axis=1, norm='ortho')\n",
    "\n",
    "X_train_dct = np.array([apply_dct(img) for img in X_train])  # Applica la DCT alle immagini di training\n",
    "X_test_dct = np.array([apply_dct(img) for img in X_test])  # Applica la DCT alle immagini di test\n",
    "\n",
    "\n",
    "print(\"Forma di X_train_dct:\", X_train_dct.shape)\n",
    "print(\"Forma di X_test_dct:\", X_test_dct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtro 1:\n",
      "[[ 0.97722438 -0.48549028  0.06127682]\n",
      " [-0.03606768  0.0917343  -0.1389121 ]\n",
      " [-0.26961112  0.36874774  0.11591712]]\n",
      "\n",
      "Filtro 2:\n",
      "[[ 2.11248623 -0.18717925 -0.08115528]\n",
      " [-0.00837894  0.05051863 -0.00576   ]\n",
      " [ 0.42908952  0.35642914  0.19320933]]\n",
      "\n",
      "Filtro 3:\n",
      "[[ 1.06669115  0.04722854  0.03681574]\n",
      " [-0.18604402 -0.75636404  0.06034862]\n",
      " [ 0.13166751  0.29198734  0.27602571]]\n",
      "\n",
      "Filtro 4:\n",
      "[[ 1.72371127  0.34437157 -0.10014884]\n",
      " [ 0.19564837 -0.35175085  0.53414074]\n",
      " [ 0.06143399 -0.51983655  0.04448111]]\n",
      "\n",
      "Filtro 5:\n",
      "[[ 1.20903258  0.03421138  0.39557056]\n",
      " [-0.16599748  0.30709143 -0.16323028]\n",
      " [-0.21476723 -0.09222288  0.22292154]]\n",
      "\n",
      "Filtro 6:\n",
      "[[ 1.46075721 -0.19133598  0.06356943]\n",
      " [-0.03234115  0.06230536  0.15576205]\n",
      " [ 0.21231456 -0.09337227 -0.32452842]]\n",
      "\n",
      "Filtro 7:\n",
      "[[ 1.31322708 -0.11489648  0.30948551]\n",
      " [-0.22073133 -0.23893432  0.19523494]\n",
      " [-0.36031242  0.09200808 -0.37581205]]\n",
      "\n",
      "Filtro 8:\n",
      "[[ 1.69278937  0.22826007  0.38077898]\n",
      " [-0.02672125 -0.4003427  -0.53594029]\n",
      " [-0.15569778 -0.17155833 -0.18103178]]\n",
      "\n",
      "Filtro 9:\n",
      "[[ 2.01782241  0.61431487 -0.31143641]\n",
      " [ 0.20210809 -0.04447842  0.03003782]\n",
      " [-0.05166117  0.23265186 -0.14178109]]\n",
      "\n",
      "Filtro 10:\n",
      "[[ 1.28379546 -0.16937081  0.36851068]\n",
      " [ 0.10721469 -0.13226287  0.42755419]\n",
      " [-0.30751327 -0.02257458 -0.12890292]]\n",
      "\n",
      "Filtro 11:\n",
      "[[ 0.99620001  0.33837513  0.02097529]\n",
      " [ 0.61029903  0.45167267 -0.13828511]\n",
      " [ 0.11252483  0.16272096 -0.15015815]]\n",
      "\n",
      "Filtro 12:\n",
      "[[ 1.49232911 -0.15118048 -0.04538443]\n",
      " [-0.13333186 -0.56573937  0.28057573]\n",
      " [-0.24511092  0.6576604   0.39716236]]\n",
      "\n",
      "Filtro 13:\n",
      "[[ 1.2551787   0.54253141 -0.06936353]\n",
      " [ 0.09873509 -0.03880206 -0.30952528]\n",
      " [-0.48796354 -0.01481691  0.05903782]]\n",
      "\n",
      "Filtro 14:\n",
      "[[ 1.50075464 -0.28205809  0.01329101]\n",
      " [-0.33990559 -0.04167411 -0.02431948]\n",
      " [ 0.59211909 -0.03633133  0.28070583]]\n",
      "\n",
      "Filtro 15:\n",
      "[[ 1.16224748 -0.05223828 -0.25308536]\n",
      " [ 0.05259407 -0.40027503 -0.04776757]\n",
      " [ 0.19301454 -0.16396325 -0.0219915 ]]\n",
      "\n",
      "Filtro 16:\n",
      "[[ 1.63808675 -0.53480445 -0.1782008 ]\n",
      " [-0.41071822  0.13308871  0.05477533]\n",
      " [-0.47284194 -0.21768207  0.00936323]]\n",
      "\n",
      "Filtro 17:\n",
      "[[ 1.37297703  0.131296    0.37943362]\n",
      " [ 0.36098775  0.37505224 -0.39543416]\n",
      " [-0.21041081  0.13176722 -0.5066352 ]]\n",
      "\n",
      "Filtro 18:\n",
      "[[ 1.703374   -0.51392233  0.09806963]\n",
      " [ 0.24186731 -0.06047804 -0.46677301]\n",
      " [ 0.24047849 -0.2307996  -0.01641026]]\n",
      "\n",
      "Filtro 19:\n",
      "[[ 1.07337836 -0.08327057 -0.12519372]\n",
      " [ 0.06071491 -0.32422643  0.16316133]\n",
      " [-0.3874248  -0.58132131  0.45910204]]\n",
      "\n",
      "Filtro 20:\n",
      "[[ 1.35003414 -0.09302114  0.07334416]\n",
      " [-0.43619531 -0.24862903  0.25867262]\n",
      " [ 0.14902511 -0.40730974 -0.43856752]]\n",
      "\n",
      "Filtro 21:\n",
      "[[ 1.67772059 -0.20162249 -0.01973237]\n",
      " [-0.2192828   0.1974779  -0.43428821]\n",
      " [-0.15654393  0.52497313  0.41824893]]\n",
      "\n",
      "Filtro 22:\n",
      "[[ 1.7422616   0.42097923  0.34974208]\n",
      " [-0.12047623  0.16755976  0.07369828]\n",
      " [ 0.04151774 -0.4110677   0.54460523]]\n",
      "\n",
      "Filtro 23:\n",
      "[[ 1.13702155 -0.27377201 -0.30304643]\n",
      " [-0.180231    0.09323579 -0.05352682]\n",
      " [ 0.00795197 -0.05510727  0.55844565]]\n",
      "\n",
      "Filtro 24:\n",
      "[[ 1.7267044  -0.15700311  0.19619285]\n",
      " [ 0.15650391  0.03629823 -0.28634299]\n",
      " [ 0.17532416  0.27712822  0.23599897]]\n",
      "\n",
      "Filtro 25:\n",
      "[[ 1.5134504  -0.00433655 -0.1128335 ]\n",
      " [ 0.16384539 -0.2312413  -0.14609866]\n",
      " [-0.12581325 -0.26936503 -0.66433589]]\n",
      "\n",
      "Filtro 26:\n",
      "[[ 1.26007976 -0.0923229   0.29249154]\n",
      " [-0.29183556  0.56958652  0.49534778]\n",
      " [-0.10240075 -0.03678724 -0.46473635]]\n",
      "\n",
      "Filtro 27:\n",
      "[[ 1.75166321  0.11502775  0.03551269]\n",
      " [ 0.03873711 -0.28760811 -0.39327669]\n",
      " [ 0.07296596 -0.3855919  -0.04995014]]\n",
      "\n",
      "Filtro 28:\n",
      "[[ 1.6238552  -0.46877044  0.38892346]\n",
      " [-0.04466732  0.15047505 -0.05336668]\n",
      " [ 0.12942655  0.24833553 -0.17961142]]\n",
      "\n",
      "Filtro 29:\n",
      "[[ 1.60536262 -0.00601455 -0.16114607]\n",
      " [ 0.20233411 -0.24125329 -0.06216356]\n",
      " [-0.76489626 -0.10449653 -0.13065878]]\n",
      "\n",
      "Filtro 30:\n",
      "[[ 1.14328335 -0.22975221 -0.33757444]\n",
      " [-0.39463277  0.24898596 -0.45043758]\n",
      " [ 0.39907768  0.03213263 -0.07144422]]\n",
      "\n",
      "Filtro 31:\n",
      "[[ 1.22130392  0.14842801 -0.44327771]\n",
      " [ 0.30489089  0.27370532 -0.48665628]\n",
      " [-0.47628939 -0.25461185 -0.13812355]]\n",
      "\n",
      "Filtro 32:\n",
      "[[ 1.37680476 -0.06642352  0.28746939]\n",
      " [ 0.14243825  0.10692585  0.04624142]\n",
      " [-0.30168511  0.19186749  0.06261278]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filtri = np.random.rand(32, 3, 3)\n",
    "\n",
    "filtri_dct = np.array([apply_dct(img) for img in filtri])  # Applica la DCT alle immagini di training\n",
    "\n",
    "\n",
    "# Stampa i filtri generati\n",
    "for i, filtro in enumerate(filtri_dct):\n",
    "    print(f\"Filtro {i+1}:\\n{filtro}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma di X_train_dct: (60000, 28, 3)\n",
      "Forma di X_test_dct: (10000, 28, 3)\n"
     ]
    }
   ],
   "source": [
    "#rimuovi tutte le colonne apparte prime 3 in tutte le immagini di training e test\n",
    "X_train_dct = X_train_dct[:, :, :3]\n",
    "X_test_dct = X_test_dct[:, :, :3]\n",
    "\n",
    "\n",
    "\n",
    "#printa le shape\n",
    "\n",
    "print(\"Forma di X_train_dct:\", X_train_dct.shape)\n",
    "print(\"Forma di X_test_dct:\", X_test_dct.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IDCTLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(IDCTLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # IDCT lungo l'asse delle righe e poi delle colonne\n",
    "        def idct_2d(tensor):\n",
    "            # Applica la IDCT lungo le righe (asse=-1)\n",
    "            x = tf.signal.idct(tensor, type=2, norm='ortho', axis=-1)\n",
    "            # Trasponi per applicare la IDCT lungo le colonne\n",
    "            x = tf.transpose(x, perm=[0, 1, 3, 2])  # Scambia -2 (righe) con -1 (colonne)\n",
    "            x = tf.signal.idct(x, type=2, norm='ortho', axis=-1)\n",
    "            # Ritorna alla disposizione originale\n",
    "            x = tf.transpose(x, perm=[0, 1, 3, 2])  # Ritorna alla forma originale\n",
    "            return x\n",
    "\n",
    "        # Applica la IDCT batch-wise e canale per canale\n",
    "        return idct_2d(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(28, 3)),  \n",
    "    Flatten(),             \n",
    "    Dense(228, activation='relu'),\n",
    "    Dense(576, activation='relu'),\n",
    "    Dense(1152, activation='relu'),\n",
    "    Reshape((3, 3, 128)),  \n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.6649 - loss: 8.3668 - val_accuracy: 0.8033 - val_loss: 0.5690\n",
      "Epoch 2/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8106 - loss: 0.5245 - val_accuracy: 0.8234 - val_loss: 0.4867\n",
      "Epoch 3/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8310 - loss: 0.4577 - val_accuracy: 0.8308 - val_loss: 0.4723\n",
      "Epoch 4/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8433 - loss: 0.4293 - val_accuracy: 0.8344 - val_loss: 0.4618\n",
      "Epoch 5/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8527 - loss: 0.4038 - val_accuracy: 0.8317 - val_loss: 0.4690\n",
      "Epoch 6/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3883 - val_accuracy: 0.8418 - val_loss: 0.4579\n",
      "Epoch 7/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3716 - val_accuracy: 0.8376 - val_loss: 0.4700\n",
      "Epoch 8/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8683 - loss: 0.3591 - val_accuracy: 0.8482 - val_loss: 0.4598\n",
      "Epoch 9/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8702 - loss: 0.3540 - val_accuracy: 0.8415 - val_loss: 0.4664\n",
      "Epoch 10/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3379 - val_accuracy: 0.8537 - val_loss: 0.4428\n",
      "Epoch 11/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.3188 - val_accuracy: 0.8467 - val_loss: 0.4532\n",
      "Epoch 12/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8861 - loss: 0.3140 - val_accuracy: 0.8487 - val_loss: 0.4529\n",
      "Epoch 13/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.3160 - val_accuracy: 0.8516 - val_loss: 0.4443\n",
      "Epoch 14/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8878 - loss: 0.3047 - val_accuracy: 0.8577 - val_loss: 0.4785\n",
      "Epoch 15/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.2887 - val_accuracy: 0.8581 - val_loss: 0.4373\n",
      "Epoch 16/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8964 - loss: 0.2802 - val_accuracy: 0.8572 - val_loss: 0.4661\n",
      "Epoch 17/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.2709 - val_accuracy: 0.8516 - val_loss: 0.4758\n",
      "Epoch 18/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.2649 - val_accuracy: 0.8562 - val_loss: 0.4870\n",
      "Epoch 19/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2473 - val_accuracy: 0.8581 - val_loss: 0.4799\n",
      "Epoch 20/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2368 - val_accuracy: 0.8515 - val_loss: 0.4954\n",
      "Epoch 21/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2377 - val_accuracy: 0.8518 - val_loss: 0.4989\n",
      "Epoch 22/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9198 - loss: 0.2172 - val_accuracy: 0.8513 - val_loss: 0.5337\n",
      "Epoch 23/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2161 - val_accuracy: 0.8521 - val_loss: 0.5432\n",
      "Epoch 24/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.2200 - val_accuracy: 0.8560 - val_loss: 0.5480\n",
      "Epoch 25/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9278 - loss: 0.1985 - val_accuracy: 0.8500 - val_loss: 0.6126\n",
      "Epoch 26/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9257 - loss: 0.2023 - val_accuracy: 0.8493 - val_loss: 0.5775\n",
      "Epoch 27/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9259 - loss: 0.2168 - val_accuracy: 0.8561 - val_loss: 0.5544\n",
      "Epoch 28/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9328 - loss: 0.1859 - val_accuracy: 0.8505 - val_loss: 0.6222\n",
      "Epoch 29/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9334 - loss: 0.1850 - val_accuracy: 0.8516 - val_loss: 0.6075\n",
      "Epoch 30/30\n",
      "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9413 - loss: 0.1601 - val_accuracy: 0.8542 - val_loss: 0.6425\n",
      "313/313 - 1s - 2ms/step - accuracy: 0.8459 - loss: 0.6838\n",
      "Test accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# Compila il modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(X_train_dct, y_train, epochs=30, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Valuta il modello\n",
    "test_loss, test_acc = model.evaluate(X_test_dct, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 GPU(s) disponibile/i.\n",
      "Epoch 1/10\n",
      "\u001b[1m319/750\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7094 - loss: 10.2375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     36\u001b[0m               loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     37\u001b[0m               metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Addestra il modello\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Valuta il modello\u001b[39;00m\n\u001b[1;32m     43\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n\u001b[1;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:217\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    214\u001b[0m     iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    215\u001b[0m ):\n\u001b[1;32m    216\u001b[0m     opt_outputs \u001b[38;5;241m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    218\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mget_value()\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/data/ops/optional_ops.py:176\u001b[0m, in \u001b[0;36m_OptionalImpl.has_value\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhas_value\u001b[39m(\u001b[38;5;28mself\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mcolocate_with(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor):\n\u001b[0;32m--> 176\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gen_optional_ops\u001b[38;5;241m.\u001b[39moptional_has_value(\n\u001b[1;32m    177\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variant_tensor, name\u001b[38;5;241m=\u001b[39mname\n\u001b[1;32m    178\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/FML/lib/python3.12/site-packages/tensorflow/python/ops/gen_optional_ops.py:172\u001b[0m, in \u001b[0;36moptional_has_value\u001b[0;34m(optional, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[1;32m    171\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m     _result \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_FastPathExecute(\n\u001b[1;32m    173\u001b[0m       _ctx, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptionalHasValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, optional)\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[1;32m    175\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Reshape\n",
    "\n",
    "# Configurazione per la GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Limita la memoria GPU allocata (opzionale)\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)  # Permette allocazione dinamica della memoria\n",
    "        print(f\"{len(gpus)} GPU(s) disponibile/i.\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"Nessuna GPU disponibile, verrà usata la CPU.\")\n",
    "\n",
    "# Carica il dataset\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "\n",
    "\n",
    "# Crea il modello\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Compila il modello\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Addestra il modello\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Valuta il modello\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test accuracy: {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
